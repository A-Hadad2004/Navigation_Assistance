{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8d3ac-a627-4a37-946a-a122af892460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import contextlib\n",
    "import math\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[1]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "if platform.system() != \"Windows\":\n",
    "    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import (\n",
    "    C3,\n",
    "    C3SPP,\n",
    "    C3TR,\n",
    "    SPP,\n",
    "    SPPF,\n",
    "    Bottleneck,\n",
    "    BottleneckCSP,\n",
    "    C3Ghost,\n",
    "    C3x,\n",
    "    Classify,\n",
    "    Concat,\n",
    "    Contract,\n",
    "    Conv,\n",
    "    CrossConv,\n",
    "    DetectMultiBackend,\n",
    "    DWConv,\n",
    "    DWConvTranspose2d,\n",
    "    Expand,\n",
    "    Focus,\n",
    "    GhostBottleneck,\n",
    "    GhostConv,\n",
    "    Proto,\n",
    ")\n",
    "from models.experimental import MixConv2d\n",
    "from utils.autoanchor import check_anchor_order\n",
    "from utils.general import LOGGER, check_version, check_yaml, colorstr, make_divisible, print_args\n",
    "from utils.plots import feature_visualization\n",
    "from utils.torch_utils import (\n",
    "    fuse_conv_and_bn,\n",
    "    initialize_weights,\n",
    "    model_info,\n",
    "    profile,\n",
    "    scale_img,\n",
    "    select_device,\n",
    "    time_sync,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import thop  # for FLOPs computation\n",
    "except ImportError:\n",
    "    thop = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39de24-3da3-4a1c-a6ae-ec51d155671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    \"\"\"YOLOv5 base model.\"\"\"\n",
    "\n",
    "    def forward(self, x, profile=False, visualize=False):\n",
    "        \"\"\"Executes a single-scale inference or training pass on the YOLOv5 base model, with options for profiling and\n",
    "        visualization.\n",
    "        \"\"\"\n",
    "        #פונקצית מעבר\n",
    "        return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
    "\n",
    "    def _forward_once(self, x, profile=False, visualize=False):\n",
    "        \"\"\"Performs a forward pass on the YOLOv5 model, enabling profiling and feature visualization options.\"\"\"\n",
    "        #פונקצית מעבר היא כוללת אפשרויות לפרופילינג- מדידת ביצועים ולוויזואליזציה- תיאור גרפי של הנתונים| של מאפיינים\n",
    "        y, dt = [], []  # outputs\n",
    "        #y: רשימה לשמירת הפלטים מכל שכבה.\n",
    "        #dt: רשימה לשמירת נתוני הפרופילינג (אם אפשרות הפרופילינג מופעלת).\n",
    "        for m in self.model:\n",
    "            #לולאה זו עוברת על כל שכבה במודל.\n",
    "            if m.f != -1:  # if not from previous layer\n",
    "                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "                #אם השכבה הנוכחית לא מקבלת את הקלט ישירות מהשכבה הקודמת, נקבל את הקלט מהשכבה שצוינה ב-m.f.\n",
    "            if profile:\n",
    "                self._profile_one_layer(m, x, dt)\n",
    "                #אם פרופילינג מופעל, נקרא לפונקציה\n",
    "                #_profile_one_layer\n",
    "                #שתבצע פרופילינג על השכבה הנוכחית.\n",
    "                #פרופילינג= תהליך של מדידת ובדיקת הביצועים של קוד או מודל\n",
    "            x = m(x)  # run\n",
    "            #הרצת הקלט דרך השכבה הנוכחית.\n",
    "            y.append(x if m.i in self.save else None)  # save output\n",
    "            #שמירת הפלט של השכבה אם היא נדרשת לשמירה (אם m.i נמצאת ברשימת השכבות שיש לשמור).\n",
    "            if visualize:\n",
    "                feature_visualization(x, m.type, m.i, save_dir=visualize)\n",
    "                #אם אפשרות הוויזואליזציה מופעלת, נקרא לפונקציה\n",
    "                #feature_visualization\n",
    "                #שתבצע וויזואליזציה על הפלט של השכבה הנוכחית.\n",
    "                # הוויזואליזציה= להצגה גרפית של הנתונים, התהליכים או התוצאות המתקבלים מהמודל\n",
    "        return x\n",
    "    #הפונקציה מחזירה את הפלט הסופי לאחר המעבר דרך כל השכבות במודל.\n",
    "\n",
    "    def _profile_one_layer(self, m, x, dt):\n",
    "        \"\"\"Profiles a single layer's performance by computing GFLOPs, execution time, and parameters.\"\"\"\n",
    "        #מבצעת פרופילינג על שכבה בודדת במודל YOLOv5, על מנת להעריך את ביצועי השכבה מבחינת\n",
    "        c = m == self.model[-1]  # is final layer, copy input as inplace fix\n",
    "        #אם זו השיכבה האחרונה, מעתיקים את הקלט כדי למנוע שינויים במקום  שעשויים לשנות את הקלט המקורי.\n",
    "        o = thop.profile(m, inputs=(x.copy() if c else x,), verbose=False)[0] / 1e9 * 2 if thop else 0  # FLOPs\n",
    "        #משתמש בספריית\n",
    "        #thop\n",
    "        #כדי לחשב את מספר הפעולות הנקודתיות\n",
    "        t = time_sync()\n",
    "        for _ in range(10):\n",
    "            m(x.copy() if c else x)\n",
    "        dt.append((time_sync() - t) * 100)\n",
    "        #מודד את זמן הביצוע של השכבה על ידי הרצתה 10 פעמים ברציפות. הזמן נמדד בשניות ומומר למילישניות ומוסף לרשימת ה-dt.\n",
    "        if m == self.model[0]:\n",
    "            LOGGER.info(f\"{'time (ms)':>10s} {'GFLOPs':>10s} {'params':>10s}  module\")\n",
    "        LOGGER.info(f\"{dt[-1]:10.2f} {o:10.2f} {m.np:10.0f}  {m.type}\")\n",
    "        if c:\n",
    "            LOGGER.info(f\"{sum(dt):10.2f} {'-':>10s} {'-':>10s}  Total\")\n",
    "            #אם השיכבה ראשונה רושמים את:הפרמטרים, הזמן,כותרת\n",
    "            #אם השכבה אחרונה רושמים את: סך כל הזמנים שלקח לכל השכבות לבצע\n",
    "\n",
    "    def fuse(self):\n",
    "        \"\"\"Fuses Conv2d() and BatchNorm2d() layers in the model to improve inference speed.\"\"\"\n",
    "        #מבצעת פעולה של מיזוג שכבות\n",
    "        LOGGER.info(\"Fusing layers... \")\n",
    "        #מדפיס הודעה ללוג המציינת שהתחיל תהליך המיזוג של השכבות.\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, (Conv, DWConv)) and hasattr(m, \"bn\"):\n",
    "                # עובר על כל השכבות במודל ובודק אם השכבה היא מסוג\n",
    "                # Conv או DWConv\n",
    "                # ויש לה מאפיין\n",
    "                # bn=(BatchNorm)\n",
    "                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv\n",
    "                # אם השכבה עומדת בתנאים, היא עוברת מיזוג עם שכבת ה\n",
    "                # -BatchNorm\n",
    "                # :שלה באמצעות הפונקציה\n",
    "                # fuse_conv_and_bn\n",
    "                delattr(m, \"bn\")  # remove batchnorm\n",
    "                # השכבה bn נמחקת מהמודל.\n",
    "                m.forward = m.forward_fuse  # update forward\n",
    "                # הפונקציה\n",
    "                # forward\n",
    "                # -של השכבה מעודכנת ל\n",
    "                # forward_fuse,\n",
    "                # שהיא פונקציה מותאמת לביצוע המיזוג.\n",
    "        self.info()\n",
    "        return self\n",
    "\n",
    "    def info(self, verbose=False, img_size=640):\n",
    "        \"\"\"Prints model information given verbosity and image size, e.g., `info(verbose=True, img_size=640)`.\"\"\"\n",
    "        #מיועדת להדפיס מידע על המודל, כגון מבנה השכבות, מספר הפרמטרים, ונתונים אחרים שעשויים להיות רלוונטיים למשתמש.\n",
    "        model_info(self, verbose, img_size)\n",
    "        #משמשת להדפסת מידע על המודל בצורה מאורגנת\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        \"\"\"Applies transformations like to(), cpu(), cuda(), half() to model tensors excluding parameters or registered\n",
    "        buffers.\n",
    "        \"\"\"\n",
    "        #משמשת ליישום טרנספורמציות על הטנזורים של המודל, כמו המרה ל\n",
    "        # CPU, ל-GPU\n",
    "        self = super()._apply(fn)\n",
    "        #הפונקציה קוראת לפונקציה\n",
    "        # _apply של המחלקה העליונה\n",
    "        # (nn.Module של PyTorch)\n",
    "        # כדי ליישם את הטרנספורמציה על כל הפרמטרים והבאפרים של המודל.\n",
    "        m = self.model[-1]  # Detect()\n",
    "        if isinstance(m, (Detect, Segment)):\n",
    "            #בודקת אם זה זיהוי או סגמנטציה אם כן מעבירה את כול הפמטרים שינוי של הפונקציה שקיבלנו\n",
    "            m.stride = fn(m.stride)\n",
    "            m.grid = list(map(fn, m.grid))\n",
    "            if isinstance(m.anchor_grid, list):\n",
    "                m.anchor_grid = list(map(fn, m.anchor_grid))\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a5824-5b00-4269-a1a7-a17841924210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ההערות שלי אחרי השורה לא לפני\n",
    "class DetectionModel(BaseModel):\n",
    "    # YOLOv5 detection model\n",
    "    def __init__(self, cfg=\"yolov5s.yaml\", ch=3, nc=None, anchors=None):\n",
    "        \"\"\"Initializes YOLOv5 model with configuration file, input channels, number of classes, and custom anchors.\"\"\"\n",
    "        #המודל קורא מקובץ ה-יאמל מציב באופן ברירת מחדל שהקלט יהיה 3\n",
    "        super().__init__()\n",
    "        #שולח למחלקת האב שלו\n",
    "        if isinstance(cfg, dict):\n",
    "            self.yaml = cfg  # model dict\n",
    "        #בודק האם המשתנה הוא דיקשנרי אם כן פשוט מציב אותו\n",
    "        else:  # is *.yaml\n",
    "            import yaml  # for torch hub\n",
    "        #אחרת הוא מייבא את הספרייה שמאפשרת קריאה של קיבצי יאמל\n",
    "\n",
    "            self.yaml_file = Path(cfg).name\n",
    "            #בגלל שכרגע המשתנה הוא רק נתיב\n",
    "            with open(cfg, encoding=\"ascii\", errors=\"ignore\") as f:\n",
    "                self.yaml = yaml.safe_load(f)  # model dict\n",
    "                #פותחת את הנתיב וטוענת את הקובץ למצב דיקשנרי\n",
    "\n",
    "        # Define model\n",
    "        #מגדירה את המודל\n",
    "        ch = self.yaml[\"ch\"] = self.yaml.get(\"ch\", ch)  # input channels\n",
    "        #מגדירה את מספר ערוצי הקלט מהדיקשנרי\n",
    "        if nc and nc != self.yaml[\"nc\"]:\n",
    "            LOGGER.info(f\"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}\")\n",
    "            self.yaml[\"nc\"] = nc  # override yaml value\n",
    "            #אם קיים כבר מספר מחלקות זאת אומרת שזה לא הפעם הראשונה ומספר המחלקות שונה מהקובץ הוא דורס את התוכן\n",
    "        if anchors:\n",
    "            LOGGER.info(f\"Overriding model.yaml anchors with anchors={anchors}\")\n",
    "            self.yaml[\"anchors\"] = round(anchors)  # override yaml value\n",
    "            #אם קיים כבר עוגנים כלומר נשלחו למחלקה הזו אז הוא דורס את מה שיש במשתנה שמייצג את הקובץ\n",
    "        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  # model, savelist\n",
    "        #השורה מעל בעצם מגדירה את השכבות של הבלוקים במודל לאחר שבשורות למעלה חילצנו את התכונות מסוימות עכשיו נחלץ את מבנה הבלוקים\n",
    "        #אנחנו נשלח העתק עמוק של הדיקשנרי יאמל לפוקצייה\n",
    "        #parse_model\n",
    "        #שהיא בעצם מחלצת את כול מבנה הבלוקים ומחזירה מבנה שכבות רציף\n",
    "        self.names = [str(i) for i in range(self.yaml[\"nc\"])]  # default names\n",
    "        #מקבל את שמות המחלקות מהקובץ\n",
    "        self.inplace = self.yaml.get(\"inplace\", True)\n",
    "        #אם מפתח קיים היא מקבלת את הערך אם לא היא מציבה \"אמת\" כברירת מחדל\n",
    "\n",
    "        # Build strides, anchors\n",
    "        m = self.model[-1]  # Detect()\n",
    "        #השיכבה האחרונה היא של החיזוי\n",
    "        if isinstance(m, (Detect, Segment)):\n",
    "            #אם המודל הוא מסוג זיהוי או סגמנטציה\n",
    "            s = 256  # 2x min stride\n",
    "            m.inplace = self.inplace\n",
    "            forward = lambda x: self.forward(x)[0] if isinstance(m, Segment) else self.forward(x)\n",
    "            #שולח למעבר רגיל בגלל שזה מודל זיהוי\n",
    "            m.stride = torch.tensor([s / x.shape[-2] for x in forward(torch.zeros(1, ch, s, s))])  # forward\n",
    "            #יוצר את החלון הזזה על ידי שליחה לפונקציית המעבר טנזור אפסים שמייצג צורה של תמונה ומחלק את ה-משתנה שמכיל 256 חלקי כול האיברים שמחזיר הטנזור\n",
    "            check_anchor_order(m)\n",
    "            #פונקצייה מטורצ' שבודקת את תקינות העוגנים\n",
    "            m.anchors /= m.stride.view(-1, 1, 1)\n",
    "            #מחלקת את העוגנים לסטרייד על מנת להביא את העוגנים הסופיים\n",
    "            self.stride = m.stride\n",
    "            self._initialize_biases()  # only run once\n",
    "            #לבדוק\n",
    "\n",
    "        # Init weights, biases\n",
    "        initialize_weights(self)\n",
    "        #מגדירה את המשקלים למשקלים התחלתיים\n",
    "        self.info()\n",
    "        LOGGER.info(\"\")\n",
    "        #הינפו יהיה ריק\n",
    "\n",
    "    def forward(self, x, augment=False, profile=False, visualize=False):\n",
    "        \"\"\"Performs single-scale or augmented inference and may include profiling or visualization.\"\"\"\n",
    "        #פוקציית מעבר רגילה\n",
    "        if augment:\n",
    "            return self._forward_augment(x)  # augmented inference, None\n",
    "        return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
    "\n",
    "    def _forward_augment(self, x):\n",
    "        \"\"\"Performs augmented inference across different scales and flips, returning combined detections.\"\"\"\n",
    "        #לשפר את הדיוק של המודל על ידי הפקת תחזיות ממספר גרסאות של אותה תמונה ולאחר מכן שילובן לתוצאה סופית אחת.\n",
    "        #מתבצע בתהליך הזיהוי או המבחן\n",
    "        img_size = x.shape[-2:]  # height, width\n",
    "        #מחלץ את גובה ורוחב התמונה המקורית.\n",
    "        s = [1, 0.83, 0.67]  # scales\n",
    "        f = [None, 3, None]  # flips (2-ud, 3-lr)\n",
    "        #s הוא רשימה של קני מידה שונים לביצוע האינפרנס.\n",
    "        #f הוא רשימה של סוגי פליפ שונים (כמו פליפ אופקי או פליפ אנכי)\n",
    "        y = []  # outputs\n",
    "        for si, fi in zip(s, f):\n",
    "            xi = scale_img(x.flip(fi) if fi else x, si, gs=int(self.stride.max()))\n",
    "            #xi הוא התמונה המוגדלת ומתהפכת בהתאם ל-scale ול-flip.\n",
    "            yi = self._forward_once(xi)[0]  # forward\n",
    "            #yi הוא הפלט של המודל לתמונה המוגדלת.\n",
    "            # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save\n",
    "            yi = self._descale_pred(yi, fi, si, img_size)\n",
    "            # מתקן את ההערכות חזרה לגודל המקורי של התמונה.\n",
    "            y.append(yi)\n",
    "            #התוצאות  של כל שלב נשמרות ברשימה.\n",
    "        y = self._clip_augmented(y)  # clip augmented tails\n",
    "        #קורא לפונקציה _clip_augmented כדי לקצץ את התוצאות המוגדלות.\n",
    "        return torch.cat(y, 1), None  # augmented inference, train\n",
    "         #משלב את כל התוצאות (detections) למימד אחד ומחזיר אותן יחדיו.\n",
    "\n",
    "    def _descale_pred(self, p, flips, scale, img_size):\n",
    "        \"\"\"De-scales predictions from augmented inference, adjusting for flips and image size.\"\"\"\n",
    "        # מיועדת להתאים את תחזיות האובייקטים שנמצאו במהלך אינפרנס מוגדל  לגודל המקורי של התמונה, ולהתאים אותן למצבי הפליפים שבוצעו\n",
    "        if self.inplace:\n",
    "            p[..., :4] /= scale  # de-scale\n",
    "            if flips == 2:\n",
    "                p[..., 1] = img_size[0] - p[..., 1]  # de-flip ud\n",
    "            elif flips == 3:\n",
    "                p[..., 0] = img_size[1] - p[..., 0]  # de-flip lr\n",
    "        else:\n",
    "            x, y, wh = p[..., 0:1] / scale, p[..., 1:2] / scale, p[..., 2:4] / scale  # de-scale\n",
    "            if flips == 2:\n",
    "                y = img_size[0] - y  # de-flip ud\n",
    "            elif flips == 3:\n",
    "                x = img_size[1] - x  # de-flip lr\n",
    "            p = torch.cat((x, y, wh, p[..., 4:]), -1)\n",
    "        return p\n",
    "\n",
    "    def _clip_augmented(self, y):\n",
    "        \"\"\"Clips augmented inference tails for YOLOv5 models, affecting first and last tensors based on grid points and\n",
    "        layer counts.\n",
    "        \"\"\"\n",
    "        #משמש במהלך תהליך האינפרנס, מעבד את התוצאות שהוגדלו ומקצץ חלקים מהן כדי לשמור על התאמה נכונה למודל.\n",
    "        nl = self.model[-1].nl  # number of detection layers (P3-P5)\n",
    "        g = sum(4**x for x in range(nl))  # grid points\n",
    "        e = 1  # exclude layer count\n",
    "        i = (y[0].shape[1] // g) * sum(4**x for x in range(e))  # indices\n",
    "        y[0] = y[0][:, :-i]  # large\n",
    "        i = (y[-1].shape[1] // g) * sum(4 ** (nl - 1 - x) for x in range(e))  # indices\n",
    "        y[-1] = y[-1][:, i:]  # small\n",
    "        return y\n",
    "\n",
    "    def _initialize_biases(self, cf=None):\n",
    "        \"\"\"\n",
    "        Initializes biases for YOLOv5's Detect() module, optionally using class frequencies (cf).\n",
    "\n",
    "        For details see https://arxiv.org/abs/1708.02002 section 3.3.\n",
    "        \"\"\"\n",
    "        #מיועדת לאתחול הטיות\n",
    "        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.\n",
    "        #cf הוא אופציונלי ומייצג את התדירות של המחלקות\n",
    "        m = self.model[-1]  # Detect() module\n",
    "        #מחלץ את המודול האחרון במודל, שהוא מודול הזיהוי (Detect).\n",
    "        for mi, s in zip(m.m, m.stride):  # from\n",
    "            #הלולאה עוברת על כל השכבות במודול הזיהוי ועל ה-strides שלהן.\n",
    "            b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)\n",
    "            #משנה את הצורה של ההטיה של השכבה הנוכחית כך שתתאים למספר העוגנים\n",
    "            b.data[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)\n",
    "            #אתחול ההטיות עבור תחזיות האובייקטים\n",
    "            b.data[:, 5 : 5 + m.nc] += (\n",
    "                math.log(0.6 / (m.nc - 0.99999)) if cf is None else torch.log(cf / cf.sum())\n",
    "            )  # cls\n",
    "            #אם cf אינו מסופק, הוא משתמש בערך ברירת מחדל המחושב על ידי הלוג של יחס 0.6 למספר המחלקות (עם תיקון קטן למניעת חלוקה באפס).\n",
    "            mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)\n",
    "            #מעדכן את ההטיה של השכבה הנוכחית ומגדיר שהיא ניתנת ללמידה\n",
    "\n",
    "\n",
    "Model = DetectionModel  # retain YOLOv5 'Model' class for backwards compatibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956a570-d47a-46df-abeb-39a9b6d3bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_model(d, ch):\n",
    "    \"\"\"Parses a YOLOv5 model from a dict `d`, configuring layers based on input channels `ch` and model architecture.\"\"\"\n",
    "    #הפונקציה  מבצעת פעולת פירוק של מודל  מתוך מבנה הנתונים שמוגדר בתוך המילון d.\n",
    "    #היא מאפשרת להגדיר את שכבות המודל על פי מבנה השכבות שהוגדר בצורה דינמית, תוך התאמה למבנה הנתונים שמועברים אליה.\n",
    "    LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")\n",
    "    anchors, nc, gd, gw, act, ch_mul = (\n",
    "        d[\"anchors\"],\n",
    "        d[\"nc\"],\n",
    "        d[\"depth_multiple\"],\n",
    "        d[\"width_multiple\"],\n",
    "        d.get(\"activation\"),\n",
    "        d.get(\"channel_multiple\"),\n",
    "    )\n",
    "    if act:\n",
    "        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()\n",
    "        LOGGER.info(f\"{colorstr('activation:')} {act}\")  # print\n",
    "    if not ch_mul:\n",
    "        ch_mul = 8\n",
    "    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors\n",
    "    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)\n",
    "\n",
    "    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out\n",
    "    for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]):  # from, number, module, args\n",
    "        m = eval(m) if isinstance(m, str) else m  # eval strings\n",
    "        for j, a in enumerate(args):\n",
    "            with contextlib.suppress(NameError):\n",
    "                args[j] = eval(a) if isinstance(a, str) else a  # eval strings\n",
    "\n",
    "        n = n_ = max(round(n * gd), 1) if n > 1 else n  # depth gain\n",
    "        if m in {\n",
    "            Conv,\n",
    "            GhostConv,\n",
    "            Bottleneck,\n",
    "            GhostBottleneck,\n",
    "            SPP,\n",
    "            SPPF,\n",
    "            DWConv,\n",
    "            MixConv2d,\n",
    "            Focus,\n",
    "            CrossConv,\n",
    "            BottleneckCSP,\n",
    "            C3,\n",
    "            C3TR,\n",
    "            C3SPP,\n",
    "            C3Ghost,\n",
    "            nn.ConvTranspose2d,\n",
    "            DWConvTranspose2d,\n",
    "            C3x,\n",
    "        }:\n",
    "            c1, c2 = ch[f], args[0]\n",
    "            if c2 != no:  # if not output\n",
    "                c2 = make_divisible(c2 * gw, ch_mul)\n",
    "\n",
    "            args = [c1, c2, *args[1:]]\n",
    "            if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}:\n",
    "                args.insert(2, n)  # number of repeats\n",
    "                n = 1\n",
    "        elif m is nn.BatchNorm2d:\n",
    "            args = [ch[f]]\n",
    "        elif m is Concat:\n",
    "            c2 = sum(ch[x] for x in f)\n",
    "        # TODO: channel, gw, gd\n",
    "        elif m in {Detect, Segment}:\n",
    "            args.append([ch[x] for x in f])\n",
    "            if isinstance(args[1], int):  # number of anchors\n",
    "                args[1] = [list(range(args[1] * 2))] * len(f)\n",
    "            if m is Segment:\n",
    "                args[3] = make_divisible(args[3] * gw, ch_mul)\n",
    "        elif m is Contract:\n",
    "            c2 = ch[f] * args[0] ** 2\n",
    "        elif m is Expand:\n",
    "            c2 = ch[f] // args[0] ** 2\n",
    "        else:\n",
    "            c2 = ch[f]\n",
    "\n",
    "        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module\n",
    "        t = str(m)[8:-2].replace(\"__main__.\", \"\")  # module type\n",
    "        np = sum(x.numel() for x in m_.parameters())  # number params\n",
    "        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params\n",
    "        LOGGER.info(f\"{i:>3}{str(f):>18}{n_:>3}{np:10.0f}  {t:<40}{str(args):<30}\")  # print\n",
    "        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist\n",
    "        layers.append(m_)\n",
    "        if i == 0:\n",
    "            ch = []\n",
    "        ch.append(c2)\n",
    "    return nn.Sequential(*layers), sorted(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9270d79-399e-4569-9327-bc182398e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cfg\", type=str, default=\"yolov5s.yaml\", help=\"model.yaml\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1, help=\"total batch size for all GPUs\")\n",
    "    parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n",
    "    parser.add_argument(\"--profile\", action=\"store_true\", help=\"profile model speed\")\n",
    "    parser.add_argument(\"--line-profile\", action=\"store_true\", help=\"profile model speed layer by layer\")\n",
    "    parser.add_argument(\"--test\", action=\"store_true\", help=\"test all yolo*.yaml\")\n",
    "    opt = parser.parse_args()\n",
    "    opt.cfg = check_yaml(opt.cfg)  # check YAML\n",
    "    print_args(vars(opt))\n",
    "    device = select_device(opt.device)\n",
    "\n",
    "    # Create model\n",
    "    im = torch.rand(opt.batch_size, 3, 640, 640).to(device)\n",
    "    model = Model(opt.cfg).to(device)\n",
    "\n",
    "    # Options\n",
    "    if opt.line_profile:  # profile layer by layer\n",
    "        model(im, profile=True)\n",
    "\n",
    "    elif opt.profile:  # profile forward-backward\n",
    "        results = profile(input=im, ops=[model], n=3)\n",
    "\n",
    "    elif opt.test:  # test all models\n",
    "        for cfg in Path(ROOT / \"models\").rglob(\"yolo*.yaml\"):\n",
    "            try:\n",
    "                _ = Model(cfg)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {cfg}: {e}\")\n",
    "\n",
    "    else:  # report fused model summary\n",
    "        model.fuse()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
